{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "330e4e60-c90c-4964-8d10-b7026ab5b5fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">77,824</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">23</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,967</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m77,824\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm_15 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m23\u001b[0m)                  │           \u001b[38;5;34m2,967\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,375</span> (829.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m212,375\u001b[0m (829.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">212,375</span> (829.59 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m212,375\u001b[0m (829.59 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "90/90 - 252s - 3s/step - loss: 2.3553 - val_loss: 2.0521\n",
      "Epoch 2/20\n",
      "90/90 - 241s - 3s/step - loss: 1.1994 - val_loss: 1.1097\n",
      "Epoch 3/20\n",
      "90/90 - 228s - 3s/step - loss: 1.0342 - val_loss: 1.1019\n",
      "Epoch 4/20\n",
      "90/90 - 231s - 3s/step - loss: 1.0227 - val_loss: 1.0781\n",
      "Epoch 5/20\n",
      "90/90 - 239s - 3s/step - loss: 1.0177 - val_loss: 1.0768\n",
      "Epoch 6/20\n",
      "90/90 - 236s - 3s/step - loss: 1.0126 - val_loss: 1.0752\n",
      "Epoch 7/20\n",
      "90/90 - 265s - 3s/step - loss: 1.0129 - val_loss: 1.0717\n",
      "Epoch 8/20\n",
      "90/90 - 235s - 3s/step - loss: 1.0118 - val_loss: 1.0747\n",
      "Epoch 9/20\n",
      "90/90 - 234s - 3s/step - loss: 1.0095 - val_loss: 1.0717\n",
      "Epoch 10/20\n",
      "90/90 - 241s - 3s/step - loss: 1.0085 - val_loss: 1.0733\n",
      "Epoch 11/20\n",
      "90/90 - 236s - 3s/step - loss: 1.0257 - val_loss: 1.0809\n",
      "Epoch 12/20\n",
      "90/90 - 243s - 3s/step - loss: 1.0112 - val_loss: 1.0707\n",
      "Epoch 13/20\n",
      "90/90 - 1576s - 18s/step - loss: 1.0083 - val_loss: 1.0724\n",
      "Epoch 14/20\n",
      "90/90 - 323s - 4s/step - loss: 1.0079 - val_loss: 1.0738\n",
      "Epoch 15/20\n",
      "90/90 - 376s - 4s/step - loss: 1.0072 - val_loss: 1.0747\n",
      "Epoch 16/20\n",
      "90/90 - 304s - 3s/step - loss: 1.0081 - val_loss: 1.0711\n",
      "Epoch 17/20\n",
      "90/90 - 303s - 3s/step - loss: 1.0080 - val_loss: 1.0730\n",
      "Epoch 18/20\n",
      "90/90 - 305s - 3s/step - loss: 1.0071 - val_loss: 1.0693\n",
      "Epoch 19/20\n",
      "90/90 - 306s - 3s/step - loss: 1.0072 - val_loss: 1.0719\n",
      "Epoch 20/20\n",
      "90/90 - 305s - 3s/step - loss: 1.0069 - val_loss: 1.0709\n",
      " [p]]\n",
      " [l] \n",
      " [d] \n",
      " [p] \n",
      " [c] \n",
      " [n] \n",
      " [d]]\n",
      " [q]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)\n",
    "\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "INPUT_FILE_NAME = 'C:/Users/Amelia/Documents/Computer Science Spring 2025/Neural Networks/GoShortenedExampleData.txt'\n",
    "WINDOW_LENGTH = 40\n",
    "WINDOW_STEP = 3\n",
    "BEAM_SIZE = 8\n",
    "NEXT_COORDINATES = 4\n",
    "MAX_LENGTH = 50\n",
    "\n",
    "file = open(INPUT_FILE_NAME, 'r', encoding='utf-8')\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "# Make lowercase and remove newline and extra spaces.\n",
    "#text = text.lower() \n",
    "text = text.replace('\\n', ' ')\n",
    "text = text.replace('  ', ' ')\n",
    "text = text.replace('B', ' ')\n",
    "text = text.replace('W', ' ')\n",
    "text = text.replace(';', ' ')\n",
    "\n",
    "# Encode characters as indices.\n",
    "unique_chars = list(set(text))\n",
    "char_to_index = dict((ch, index) for index, ch \n",
    "                     in enumerate(unique_chars))\n",
    "index_to_char = dict((index, ch) for index, ch \n",
    "                     in enumerate(unique_chars))\n",
    "encoding_width = len(char_to_index)\n",
    "\n",
    "fragments = []\n",
    "targets = []\n",
    "for i in range(0, len(text) - WINDOW_LENGTH, WINDOW_STEP):\n",
    "    fragments.append(text[i: i + WINDOW_LENGTH])\n",
    "    targets.append(text[i + WINDOW_LENGTH])\n",
    "# Convert to one-hot encoded training data.\n",
    "X = np.zeros((len(fragments), WINDOW_LENGTH, encoding_width))\n",
    "y = np.zeros((len(fragments), encoding_width))\n",
    "for i, fragment in enumerate(fragments):\n",
    "    for j, char in enumerate(fragment):\n",
    "        X[i, j, char_to_index[char]] = 1\n",
    "    target_char = targets[i]\n",
    "    y[i, char_to_index[target_char]] = 1\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True,\n",
    "               dropout=0.2, recurrent_dropout=0.2,\n",
    "               input_shape=(None, encoding_width)))\n",
    "model.add(LSTM(128, dropout=0.2,\n",
    "               recurrent_dropout=0.2))\n",
    "model.add(Dense(encoding_width, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam')\n",
    "model.summary()\n",
    "history = model.fit(X, y, validation_split=0.05,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS, verbose=2,\n",
    "                    shuffle=True)\n",
    "\n",
    "#text prediction\n",
    "\n",
    "next_move = ' ' \n",
    "one_hots = []\n",
    "for i, char in enumerate(next_move):\n",
    "    x = np.zeros(encoding_width)\n",
    "    x[char_to_index[char]] = 1\n",
    "    one_hots.append(x)\n",
    "beams = [(np.log(1.0), next_move, one_hots)]\n",
    "\n",
    "# Predict next coordinates for game.\n",
    "for i in range(NEXT_COORDINATES):\n",
    "    minibatch_list = []\n",
    "    # Create minibatch from one-hot encodings, and predict.\n",
    "    for triple in beams:\n",
    "        minibatch_list.append(triple[2])\n",
    "    minibatch = np.array(minibatch_list)\n",
    "    y_predict = model.predict(minibatch, verbose=0)\n",
    "    new_beams = []\n",
    "    for j, softmax_vec in enumerate(y_predict):\n",
    "        triple = beams[j]\n",
    "        # Create BEAM_SIZE new beams from each existing beam.\n",
    "        for k in range(BEAM_SIZE):\n",
    "            char_index = np.argmax(softmax_vec)\n",
    "            new_prob = triple[0] + np.log(\n",
    "                softmax_vec[char_index])\n",
    "            new_letters = triple[1] + index_to_char[char_index]\n",
    "            x = np.zeros(encoding_width)\n",
    "            x[char_index] = 1\n",
    "            new_one_hots = triple[2].copy()\n",
    "            new_one_hots.append(x)\n",
    "            new_beams.append((new_prob, new_letters,\n",
    "                              new_one_hots))\n",
    "            softmax_vec[char_index] = 0\n",
    "    # Prune tree to only keep BEAM_SIZE most probable beams.\n",
    "    new_beams.sort(key=lambda tup: tup[0], reverse=True)\n",
    "    beams = new_beams[0:BEAM_SIZE]\n",
    "for item in beams:\n",
    "    print(item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22bf57a-bb6f-4f9e-856f-3e452da2801e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
